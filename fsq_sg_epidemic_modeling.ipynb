{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdb\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import numpy as np \n",
    "import uuid\n",
    "import numpy.random as npr\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import itertools\n",
    "import copy\n",
    "import time\n",
    "import scipy\n",
    "import scipy.stats as sps\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem()\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa55a6",
   "metadata": {},
   "source": [
    "# Epidemic modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_states(pop_geoid, params,model='SEIR'):\n",
    "    if 'S' not in params.keys():\n",
    "        sys.exit(\"Initial conditions must be in params to use this method\")\n",
    "    states = pd.DataFrame(index=pop_geoid.index)\n",
    "    states['N'] = pop_geoid['pop'].copy() #total population\n",
    "    probs = states['N']/np.sum(states['N'])\n",
    "\n",
    "    N_minus_S = np.sum(states['N']) - params['S']\n",
    "    N_minus_S  = npr.multinomial(int(N_minus_S), pvals = probs) \n",
    "\n",
    "    states['S'] = states['N'] - N_minus_S \n",
    "    states['S'] = states[['N','S']].min(axis=1)\n",
    "    states['S/N'] = states['S']/states['N']\n",
    "\n",
    "    states['E'] = npr.multinomial(int(params['E']), pvals = probs) \n",
    "    states['E'] = states[['N','E']].min(axis=1)\n",
    "\n",
    "    states['I'] = npr.multinomial(int(params['I']), pvals = probs) \n",
    "    states['I'] = states[['N','I']].min(axis=1)\n",
    "\n",
    "    if model == 'SEIIR':\n",
    "        states['I_s'] = (states['I']*params['rho']).round()\n",
    "        states['I_a'] = (states['I']*(1-params['rho'])).round()\n",
    "        states['I_s/N'] = states['I_s']/states['N']\n",
    "        states['I_a/N'] = states['I_a']/states['N']\n",
    "        states['I'] = None\n",
    "    elif model == 'SEIR':\n",
    "        states['I/N'] = states['I']/states['N']\n",
    "    else:\n",
    "        sys.exit('model not programmed')\n",
    "    return(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23108c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rate_SEIR(df, beta):\n",
    "    edge_rate = beta*df['S/N']*df['I/N']*df['expected_contacts_sq_ft']\n",
    "    effective_rate = pd.Series(edge_rate,name='rate')\n",
    "    effective_rate['origin_geoid'] = df['origin_geoid']\n",
    "    effective_rate = effective_rate.groupby('origin_geoid').sum()\n",
    "    return(effective_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transitions(states, effective_rates, params,model='SEIR', log_p=False):   \n",
    "    tr = pd.DataFrame(index=states.index)\n",
    "    #First fill a dataframe with rates\n",
    "#     print('In S_E part 1:',effective_rates.isnull().sum())\n",
    "#     print(tr.shape,len(effective_rates))\n",
    "    tr['S_to_E'] = effective_rates\n",
    "#     print('In S_E:',tr['S_to_E'].isnull().sum())\n",
    "    tr['E_to_I'] = params['kappa']*states['E']\n",
    "    if model == 'SEIR':\n",
    "        tr['I_to_R'] = params['gamma']*states['I']\n",
    "        if log_p: rates = tr.copy()\n",
    "#         print(tr[['S_to_E', 'E_to_I', 'I_to_R']].isnull().sum())\n",
    "#         print(tr[['S_to_E', 'E_to_I', 'I_to_R']].shape)\n",
    "        tr.loc[:,['S_to_E', 'E_to_I', 'I_to_R']] = npr.poisson(\n",
    "            tr[['S_to_E', 'E_to_I', 'I_to_R']])\n",
    "        if log_p:\n",
    "            p=np.sum(sps.poisson.logpmf(mu=rates, k=tr))\n",
    "            return(tr, p)\n",
    "        else:\n",
    "            return(tr)\n",
    "    elif model == 'SEIIR':\n",
    "        tr['Is_to_R'] = params['gamma']*states['I_s']\n",
    "        tr['Ia_to_R'] = params['gamma']*states['I_a']\n",
    "        #Sample Poissons with the array of rates all at once.\n",
    "        tr.loc[:,['S_to_E', 'E_to_I', 'Is_to_R', 'Ia_to_R']] = npr.poisson(\n",
    "            tr[['S_to_E', 'E_to_I', 'Is_to_R', 'Ia_to_R']])\n",
    "\n",
    "        tr['S_to_E'] = tr[['S_to_E', 'S']].min(axis=1)\n",
    "        tr['E_to_I'] = tr[['E_to_I', 'E']].min(axis=1)\n",
    "        tr['Is_to_R'] = tr[['Is_to_R', 'I_s']].min(axis=1)\n",
    "        tr['Ia_to_R'] = tr[['Ia_to_R', 'I_a']].min(axis=1)\n",
    "        return(tr)\n",
    "    else:\n",
    "        sys.exit('model not programmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02449530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transitions(states, trans, params, model='SEIR'):\n",
    "    trans = pd.concat([trans, states[['S', 'E', 'I']]], axis=1)\n",
    "    trans['S_to_E'] = trans[['S_to_E', 'S']].min(axis=1)\n",
    "    trans['E_to_I'] = trans[['E_to_I', 'E']].min(axis=1)\n",
    "    trans['I_to_R'] = trans[['I_to_R', 'I']].min(axis=1)\n",
    "\n",
    "    states['S'] += -trans['S_to_E']\n",
    "    states['E'] += trans['S_to_E'] - trans['E_to_I'] \n",
    "    if model == 'SEIR':\n",
    "        states['I'] += trans['E_to_I'] - trans['I_to_R']\n",
    "        states['I/N'] = states['I']/states['N']\n",
    "    elif model == 'SEIIR':\n",
    "        states['I_s'] += (params['rho']*trans['E_to_I']).round() - trans['Is_to_R']\n",
    "        states['I_a'] += ((1. -params['rho'])*trans['E_to_I']).round() - trans['Ia_to_R'] \n",
    "        states['I_s/N'] = states['I_s']/states['N']\n",
    "        states['I_a/N'] = states['I_a']/states['N']\n",
    "    else:\n",
    "        sys.exit('model not programmed')\n",
    "    states['S/N'] = states['S']/states['N']\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800217ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_states(states, params, net, model='SEIR', log_p=False):\n",
    "    \"\"\"\n",
    "    Takes the states of the model in a given day and simulates the \n",
    "    compartmental transitions. The only non-static parameter, is the \n",
    "    contact network. \n",
    "    params:\n",
    "        states: dict\n",
    "            current compartment counts for every subpopulation.\n",
    "        alpha: float\n",
    "            discount factor for contact with an asymptomatic infective.\n",
    "        beta: float\n",
    "            rate of infection the probability of a susceptible becoming \n",
    "            infected from exposure to one infective/sq_foot. \n",
    "        gamma: float\n",
    "            rate at which infectives recover.\n",
    "        kappa: float\n",
    "            rate at which an exposed becomes infective.\n",
    "        rho: float\n",
    "            probability of exposed becoming symptomatic.\n",
    "        net: pandas DataFrame\n",
    "            network estimating the number of contacts with other CBGs\n",
    "            in a given day.\n",
    "        net: dict\n",
    "            contact network with double index (origin_geoid, dest_geoid) \n",
    "        model: str\n",
    "            the type of compartmental model\n",
    "        out_trans: bool\n",
    "            if trans, we return the transitions\n",
    "            for likelihood computation\n",
    "    \"\"\"\n",
    "    #compute effective infection rates\n",
    "    net = net.join(states['S/N'], on='origin_geoid')\n",
    "    if model == 'SEIIR':\n",
    "        net = net.join(\n",
    "            states[['I_a/N', 'I_s/N']],\n",
    "            on='destination_geoid')\n",
    "        effective_rates = compute_rate(\n",
    "            net,\n",
    "            states=states,\n",
    "            alpha=params['alpha'],\n",
    "            beta=params['beta'])\n",
    "    elif model == 'SEIR':\n",
    "        net = net.join(states['I/N'], on='destination_geoid')\n",
    "        effective_rates = compute_rate_SEIR(\n",
    "            net,\n",
    "            beta=params['beta'])\n",
    "    #sample state transitions\n",
    "#     print('123 count nulls:',effective_rates.isnull().sum())\n",
    "    if log_p:\n",
    "        trans, p = state_transitions(states, effective_rates, params, model, log_p)\n",
    "        apply_transitions(states, trans, params, model)\n",
    "        return(states, trans['E_to_I'], p)\n",
    "    else:\n",
    "        trans = state_transitions(states, effective_rates, params, model)\n",
    "        apply_transitions(states, trans, params, model)\n",
    "        return((states, trans['E_to_I']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(path, date, index_dict, net_type='fsq'):\n",
    "    \n",
    "    pivot_table = pd.read_csv(f'{path}{date}.csv').iloc[:,1:] # ct_to_ct\n",
    "#     print('Shape heres:',pivot_table.shape)\n",
    "    net = pd.melt(pivot_table, id_vars=['home_CT'], var_name='column_name', value_name='value')\n",
    "    net = net.rename(columns={'home_CT':'origin_geoid','column_name':'destination_geoid','value':'expected_contacts'})\n",
    "    \n",
    "    # filter those in pop_df.index\n",
    "    net = net[(net.origin_geoid.isin(pop_df.index)) & (net.destination_geoid.isin(pop_df.index))]\n",
    "    \n",
    "    net['origin_geoid'] = net.origin_geoid.astype(str)\n",
    "    net['destination_geoid'] = net.destination_geoid.astype(str)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(params,\n",
    "              path,\n",
    "              pop_geoid,\n",
    "              index_dict,\n",
    "              net_type,\n",
    "              date_interval,\n",
    "              model='SEIR',\n",
    "              num_sims=36,\n",
    "              initial_cond=None):\n",
    "    \n",
    "#     caseload_df = pd.DataFrame({'date':date_interval})\n",
    "    caseload_df = pd.DataFrame(columns=['iterate', 'date', 'census_tract', 'new_cases'])\n",
    "\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(range(num_sims)):\n",
    "        if initial_cond is not None:\n",
    "            states = initialize_states_list(\n",
    "                initial_cond,\n",
    "                i,\n",
    "                pop_geoid)\n",
    "        else:\n",
    "            states = initialize_states(\n",
    "                pop_geoid,\n",
    "                params=params)\n",
    "        \n",
    "        caseload = []\n",
    "        patterns_date = ''\n",
    "        for date in date_interval:\n",
    "            print(f\"Simulating for date {date}\")\n",
    "\n",
    "            net=get_net(path, date, index_dict, net_type)\n",
    "            net = net.merge(pop_geoid.reset_index(), left_on='destination_geoid',right_on='index',how='left')[list(net.columns) + ['area']]\n",
    "            net['expected_contacts_sq_ft'] = net.expected_contacts / net.area\n",
    "\n",
    "            states, new_cases = update_states(\n",
    "                states=states,\n",
    "                params=params,\n",
    "                net=net)\n",
    "#             caseload.append(new_cases) # new_cases \n",
    "            for ct, cases in zip(new_cases.index, new_cases.values):\n",
    "                caseload_df = caseload_df.append({'iterate': i, 'date': date, 'census_tract': ct, 'new_cases': cases}, ignore_index=True)\n",
    "\n",
    "    # Set the index of caseload_df\n",
    "#     caseload_df.set_index(['date', 'census_tract'], inplace=True)\n",
    "\n",
    "#         caseload_df[i]=caseload\n",
    "#     caseload_df.set_index('date',inplace=True)\n",
    "#     caseload_df = caseload_df.groupby(['date','census_tract']).mean()\n",
    "    caseload_df['new_cases'] = pd.to_numeric(caseload_df['new_cases'], errors='coerce')\n",
    "#     caseload_df = caseload_df.groupby(['date','census_tract']).mean()\n",
    "#     new_df = df.pivot(index='Index1', columns='Value', values='Value').fillna(0)\n",
    "\n",
    "    caseload_df = caseload_df.pivot(index=['date','census_tract'], columns='iterate', values='new_cases').fillna(0)\n",
    "\n",
    "    return (caseload_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f51c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get populations\n",
    "def get_pop():\n",
    "    cbg_pops = pd.read_csv('./tmp/populations_cbg.csv')\n",
    "\n",
    "    cbgs = gpd.read_file(\"./tmp/Census_Block_Groups_2010.geojson\", crs=4326)\n",
    "    cbgs = cbgs.loc[cbgs.GEOID10.apply(lambda x: x[:5] == \"42101\"), [\"GEOID10\",\"geometry\", \"Shape__Area\"]]\n",
    "\n",
    "    cbg_pops['GEOID'] = cbg_pops.GEOID.astype(str)\n",
    "    cbg_pops = cbg_pops.loc[cbg_pops.GEOID.apply(lambda x: x[:5] == \"42101\")]\n",
    "    cbg_pops['CT'] = cbg_pops.GEOID.apply(lambda x: x[:-1])\n",
    "    cbg_pops = cbg_pops.merge(cbgs, left_on='GEOID', right_on='GEOID10',how='left')\n",
    "\n",
    "    ct_pops = cbg_pops.groupby('CT')[['B01003_001_Population', 'Shape__Area']].sum().reset_index()\n",
    "\n",
    "    pop_dict = ct_pops.set_index('CT').to_dict()\n",
    "\n",
    "    pop_df = pd.DataFrame.from_dict(pop_dict)\n",
    "    pop_df = pop_df.rename({'B01003_001_Population':'pop', 'Shape__Area':'area'},axis=1).sort_index()\n",
    "    return pop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd5ad9",
   "metadata": {},
   "source": [
    "# Run epidemic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebdd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'beta' : 2000,\n",
    "        'kappa' : 0.22,\n",
    "        'gamma' : 0.14,\n",
    "        'tau' : 0.08\n",
    "}\n",
    "\n",
    "start = datetime.strptime(\"04-01-2020\", \"%m-%d-%Y\")\n",
    "end = datetime.strptime(\"04-30-2020\", \"%m-%d-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "date_interval = [date.strftime(\"%Y-%m-%d\") for date in date_generated]\n",
    "\n",
    "path = \"s3://phl-poi-networks/fsq/\"\n",
    "net_type = \"fsq\"\n",
    "\n",
    "pop_df = get_pop()\n",
    "\n",
    "bip = pd.read_csv((f'{path}{date_interval[0]}.csv'), index_col=0).reset_index()\n",
    "index_dict = bip['home_CT'].to_dict()\n",
    "\n",
    "# restrict pop_geoid to just CTs in bip\n",
    "pop_df = pop_df[pop_df.index.isin(bip.home_CT.astype(str))]\n",
    "\n",
    "philly_pop = pop_df['pop'].sum()\n",
    "params['E'] = 100\n",
    "params['S'] = philly_pop - params['E']\n",
    "params['I'] = 0\n",
    "\n",
    "test_fsq = run_model(params, path, pop_df, index_dict, net_type, date_interval, num_sims=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_sum_fsq = test_fsq.groupby('date').sum()\n",
    "date_sum_fsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'beta' : 2000,\n",
    "        'kappa' : 0.22,\n",
    "        'gamma' : 0.14,\n",
    "        'tau' : 0.08\n",
    "}\n",
    "\n",
    "start = datetime.strptime(\"04-01-2020\", \"%m-%d-%Y\")\n",
    "end = datetime.strptime(\"04-30-2020\", \"%m-%d-%Y\")\n",
    "date_generated = [start + timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "date_interval = [date.strftime(\"%Y-%m-%d\") for date in date_generated]\n",
    "\n",
    "path = \"s3://phl-poi-networks/stanford/\"\n",
    "net_type = \"sg\"\n",
    "\n",
    "pop_df = get_pop()\n",
    "\n",
    "bip = pd.read_csv((f'{path}{date_interval[0]}.csv'), index_col=0).reset_index()\n",
    "index_dict = bip['home_CT'].to_dict()\n",
    "\n",
    "# restrict pop_geoid to just CTs in bip\n",
    "pop_df = pop_df[pop_df.index.isin(bip.home_CT.astype(str))]\n",
    "\n",
    "philly_pop = pop_df['pop'].sum()\n",
    "params['E'] = 100\n",
    "params['S'] = philly_pop - params['E']\n",
    "params['I'] = 0\n",
    "\n",
    "test_sg = run_model(params, path, pop_df, index_dict, net_type, date_interval, num_sims=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ece01",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_sum_sg = test_sg.groupby('date').sum()\n",
    "date_sum_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_fsq = np.quantile(date_sum_fsq, [0.1, 0.5, 0.9], axis=1).transpose()\n",
    "quantile_fsq = pd.DataFrame(quantile_fsq, columns = ['low_fsq', 'median_fsq', 'high_fsq'], index=date_sum_fsq.index)\n",
    "quantile_fsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97610e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_sg = np.quantile(date_sum_sg, [0.1, 0.5, 0.9], axis=1).transpose()\n",
    "quantile_sg = pd.DataFrame(quantile_sg, columns = ['low_sg', 'median_sg', 'high_sg'], index=date_sum_sg.index)\n",
    "quantile_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46365aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = quantile_fsq.join(quantile_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = quantile.index\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_axis,\n",
    "    quantile['median_fsq'],\n",
    "    marker='',\n",
    "    color='skyblue',\n",
    "    linewidth=2,\n",
    "    label = 'fsq')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "#plot confidence\n",
    "plt.fill_between(\n",
    "    x_axis,\n",
    "    quantile['low_fsq'],\n",
    "    quantile['high_fsq'],\n",
    "    color='b',\n",
    "    alpha=.1)\n",
    "\n",
    "ax.plot(x_axis,\n",
    "    quantile['median_sg'],\n",
    "    marker='',\n",
    "    color='red',\n",
    "    linewidth=2,\n",
    "    label = 'sg')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "#plot confidence\n",
    "plt.fill_between(\n",
    "    x_axis,\n",
    "    quantile['low_sg'],\n",
    "    quantile['high_sg'],\n",
    "    color='r',\n",
    "    alpha=.1)\n",
    "plt.title('Simulated epidemic (PHL)', fontsize=18)\n",
    "plt.grid()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "# fig.autofmt_xdate()\n",
    "# xfmt = mdates.DateFormatter('%m-%d')\n",
    "# ax.xaxis.set_major_formatter(xfmt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6950e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Assuming you have already defined the x_axis and quantile DataFrame\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x_axis,\n",
    "        quantile['median_fsq'],\n",
    "        marker='',\n",
    "        color='skyblue',\n",
    "        linewidth=2,\n",
    "        label='fsq')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot confidence\n",
    "plt.fill_between(\n",
    "    x_axis,\n",
    "    quantile['low_fsq'],\n",
    "    quantile['high_fsq'],\n",
    "    color='b',\n",
    "    alpha=.1)\n",
    "\n",
    "ax.plot(x_axis,\n",
    "        quantile['median_sg'],\n",
    "        marker='',\n",
    "        color='red',\n",
    "        linewidth=2,\n",
    "        label='sg')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot confidence\n",
    "plt.fill_between(\n",
    "    x_axis,\n",
    "    quantile['low_sg'],\n",
    "    quantile['high_sg'],\n",
    "    color='r',\n",
    "    alpha=.1)\n",
    "\n",
    "plt.title('Simulated epidemic (PHL)', fontsize=18)\n",
    "plt.grid()\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "# Set the x-axis limits from April 1st to April 29th\n",
    "start_date = pd.to_datetime('2022-04-01')\n",
    "end_date = pd.to_datetime('2022-04-29')\n",
    "plt.xlim(start_date, end_date)\n",
    "\n",
    "# Customize x-axis tick labels to show dates at weekly intervals\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fe096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fsq.mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sg.mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d523f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('s3://upenn-seas-wattscovid19lab/paco/acs_vars/safegraph_open_census_data/data/data/cbg_b01.csv', dtype={'census_block_group':str})\n",
    "# Shorten census_block_group to census_tract, convert population to int and group by census_tract\n",
    "population = population.assign(\n",
    "    census_tract = population['census_block_group'].str[:-1],\n",
    "    population = population['B01003e1'].astype(int)).groupby('census_tract')['population'].sum()\n",
    "\n",
    "population = population[population.index.str.startswith('42101')&(population>5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cases = test_fsq.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d248a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg_pops = pd.read_csv('./tmp/populations_cbg.csv')\n",
    "\n",
    "cbgs = gpd.read_file(\"s3://upenn-seas-wattscovid19lab/paco/geometry/Census_Tracts_2010.geojson\", crs=4326)\n",
    "cbgs = cbgs.loc[cbgs.GEOID10.apply(lambda x: x[:5] == \"42101\"), [\"GEOID10\",\"geometry\"]]\n",
    "\n",
    "cbg_pops['CT'] = cbg_pops.GEOID.astype(str).apply(lambda x: x[:-1])\n",
    "\n",
    "ct_pops = cbg_pops.groupby('CT')['B01003_001_Population'].sum().reset_index()\n",
    "\n",
    "pop_dict = ct_pops.set_index('CT').to_dict()['B01003_001_Population']\n",
    "\n",
    "pop_df = pd.DataFrame.from_dict(pop_dict, orient='index', columns=['pop']).reset_index().rename({'index':'home_CT'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd889432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg_plot = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot by visits scaled by CT\n",
    "phila_poly = gpd.GeoDataFrame(geometry= gpd.GeoSeries([cbgs.geometry.unary_union.buffer(0.000008)], crs=4326))\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(24,10))\n",
    "fig.suptitle(f'Heatmap of Normalized Visits on April 1 (Chang)',fontsize=24)\n",
    "\n",
    "cmap='YlOrRd'\n",
    "divnorm=colors.TwoSlopeNorm(vmin=cbg_plot.scaled_visits.min(), vcenter=cbg_plot.scaled_visits.quantile(0.5), vmax=cbg_plot.scaled_visits.max())\n",
    "phila_poly.plot(facecolor=\"lightgray\", edgecolor=\"white\", ax=ax)\n",
    "cbg_plot.plot(column='scaled_visits', cmap=cmap, norm=divnorm, ax=ax)\n",
    "ax.set_xticks([], minor=False)\n",
    "ax.set_yticks([], minor=False)\n",
    "\n",
    "cbar = plt.cm.ScalarMappable(norm=divnorm, cmap=cmap)\n",
    "cbar_ax = fig.add_axes([0.62, 0.05, 0.15, 0.86])\n",
    "cbar_ax.set_axis_off()\n",
    "cbar = fig.colorbar(cbar, ax=cbar_ax, extend='both')\n",
    "cbar.set_label('Scaled Visits', fontsize=24, rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('chang_apr1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e7e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
